{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install groq\n",
        "!pip install jsonlines"
      ],
      "metadata": {
        "id": "FztQ4_ixoaNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import pandas as pd\n",
        "import requests\n",
        "from groq import Groq\n",
        "from google.colab import drive\n",
        "from IPython.display import display, HTML\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Install required packages\n",
        "!pip install groq pandas tqdm requests\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project directory if it doesn't exist\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/socratic_project\"\n",
        "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
        "print(f\"Project directory created at: {PROJECT_DIR}\")\n",
        "\n",
        "# Setup Groq client\n",
        "# You'll need to add your API key\n",
        "API_KEY = input(\"Enter your Groq API key: \")\n",
        "os.environ[\"GROQ_API_KEY\"] = API_KEY\n",
        "client = Groq(api_key=API_KEY)\n",
        "\n",
        "# Function to parse the socratic dialogue from model output\n",
        "def parse_dialogue(text):\n",
        "    # First, try to extract JSON directly if it exists\n",
        "    try:\n",
        "        # Find JSON pattern with regex\n",
        "        json_pattern = r'\\[\\s*\\{.*\\}\\s*\\]'\n",
        "        match = re.search(json_pattern, text, re.DOTALL)\n",
        "        if match:\n",
        "            dialogue = json.loads(match.group(0))\n",
        "            return dialogue\n",
        "    except:\n",
        "        print(\"JSON extraction failed, trying manual parsing\")\n",
        "\n",
        "    # Manual parsing as fallback\n",
        "    dialogue = []\n",
        "    lines = text.split('\\n')\n",
        "    current_role = None\n",
        "    current_content = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            continue\n",
        "\n",
        "        # Check for teacher/student markers\n",
        "        if re.match(r'^(Teacher|TEACHER|teacher):', line):\n",
        "            if current_role:\n",
        "                dialogue.append({\"role\": current_role, \"content\": \" \".join(current_content).strip()})\n",
        "            current_role = \"teacher\"\n",
        "            content_part = re.split(r'^(Teacher|TEACHER|teacher):\\s*', line)[2] if len(re.split(r'^(Teacher|TEACHER|teacher):\\s*', line)) > 2 else \"\"\n",
        "            current_content = [content_part]\n",
        "        elif re.match(r'^(Student|STUDENT|student):', line):\n",
        "            if current_role:\n",
        "                dialogue.append({\"role\": current_role, \"content\": \" \".join(current_content).strip()})\n",
        "            current_role = \"student\"\n",
        "            content_part = re.split(r'^(Student|STUDENT|student):\\s*', line)[2] if len(re.split(r'^(Student|STUDENT|student):\\s*', line)) > 2 else \"\"\n",
        "            current_content = [content_part]\n",
        "        elif current_role:\n",
        "            current_content.append(line.strip())\n",
        "\n",
        "    # Add the last dialogue turn\n",
        "    if current_role and current_content:\n",
        "        dialogue.append({\"role\": current_role, \"content\": \" \".join(current_content).strip()})\n",
        "\n",
        "    # If parsing failed completely, create a placeholder\n",
        "    if not dialogue:\n",
        "        print(\"Warning: Could not parse dialogue structure. Using raw text.\")\n",
        "        dialogue = [{\"role\": \"teacher\", \"content\": text}]\n",
        "\n",
        "    return dialogue\n",
        "\n",
        "# Instead of using files.upload(), manually upload the file to your Google Drive\n",
        "# and then access it directly\n",
        "print(\"\\nPlease upload your class7.txt file to Google Drive in the socratic_project folder\")\n",
        "print(\"Once uploaded, enter the filename below:\")\n",
        "\n",
        "input_file = input(\"Filename (default: class7.txt): \") or \"class7.txt\"\n",
        "file_path = f\"{PROJECT_DIR}/{input_file}\"\n",
        "\n",
        "# Check if file exists\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"File not found at {file_path}\")\n",
        "    print(\"Please upload the file to your Google Drive and try again.\")\n",
        "    import sys\n",
        "    sys.exit()\n",
        "\n",
        "# Read the questions from the file\n",
        "with open(file_path, \"r\") as f:\n",
        "    questions_raw = f.readlines()\n",
        "\n",
        "# Clean up questions and visualize them\n",
        "questions = [q.strip() for q in questions_raw if q.strip()]\n",
        "\n",
        "# Display the questions in a DataFrame for verification\n",
        "df_questions = pd.DataFrame({\n",
        "    \"Question Number\": range(1, len(questions) + 1),\n",
        "    \"Question\": questions\n",
        "})\n",
        "\n",
        "print(f\"\\nLoaded {len(questions)} questions. Here's a preview:\")\n",
        "display(df_questions.head(10))\n",
        "\n",
        "# Ask user to verify questions look correct before proceeding\n",
        "proceed = input(\"\\nDo the questions look correctly separated? (yes/no): \")\n",
        "if proceed.lower() not in ['yes', 'y']:\n",
        "    print(\"Please fix the input file and re-run.\")\n",
        "    import sys\n",
        "    sys.exit()\n",
        "\n",
        "# Define how many questions to process (full dataset or sample)\n",
        "process_all = input(\"\\nProcess all questions or just a sample? (all/sample): \")\n",
        "if process_all.lower() in ['sample', 's']:\n",
        "    sample_size = int(input(\"How many questions to process? (e.g., 5): \"))\n",
        "    questions = questions[:sample_size]\n",
        "    print(f\"Processing a sample of {sample_size} questions.\")\n",
        "else:\n",
        "    print(f\"Processing all {len(questions)} questions.\")\n",
        "\n",
        "# Function to find latest checkpoint\n",
        "def find_latest_checkpoint():\n",
        "    try:\n",
        "        checkpoint_files = [f for f in os.listdir(PROJECT_DIR)\n",
        "                           if f.startswith(\"checkpoint_\") and f.endswith(\".json\")]\n",
        "        if not checkpoint_files:\n",
        "            return 0, []\n",
        "\n",
        "        latest_file = max(checkpoint_files, key=lambda x: int(x.split(\"_\")[1].split(\".\")[0]))\n",
        "        latest_idx = int(latest_file.split(\"_\")[1].split(\".\")[0])\n",
        "\n",
        "        with open(f\"{PROJECT_DIR}/{latest_file}\", \"r\") as f:\n",
        "            completed_results = json.load(f)\n",
        "\n",
        "        return latest_idx, completed_results\n",
        "    except Exception as e:\n",
        "        print(f\"Error finding checkpoints: {e}\")\n",
        "        return 0, []\n",
        "\n",
        "# Call API with retry\n",
        "def call_groq_with_retry(prompt, model=\"llama3-70b-8192\", max_tokens=2000, max_retries=5):\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                model=model,\n",
        "                max_tokens=max_tokens\n",
        "            )\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            wait_time = 2 ** attempt  # Exponential backoff\n",
        "            print(f\"Error calling Groq API: {e}. Retrying in {wait_time} seconds...\")\n",
        "            time.sleep(wait_time)\n",
        "\n",
        "    # If all retries fail\n",
        "    raise Exception(f\"Failed to call Groq API after {max_retries} attempts\")\n",
        "\n",
        "# Constants for processing\n",
        "CHECKPOINT_FREQUENCY = 25  # Save every 25 questions\n",
        "BATCH_SIZE = 50  # Process in batches of 50 questions\n",
        "\n",
        "# Check for existing checkpoints\n",
        "start_idx, results = find_latest_checkpoint()\n",
        "if start_idx > 0:\n",
        "    print(f\"Resuming from question {start_idx} with {len(results)} completed results\")\n",
        "else:\n",
        "    results = []\n",
        "\n",
        "# Create tracking DataFrame\n",
        "tracking_data = []\n",
        "for i, q in enumerate(questions):\n",
        "    status = \"Completed\" if i < start_idx else \"Pending\"\n",
        "    tracking_data.append({\"Question\": q, \"Status\": status, \"Factual Answer\": \"\", \"Dialogue Turns\": 0})\n",
        "\n",
        "results_tracking = pd.DataFrame(tracking_data)\n",
        "\n",
        "# Process each batch\n",
        "for batch_start in range(start_idx, len(questions), BATCH_SIZE):\n",
        "    batch_end = min(batch_start + BATCH_SIZE, len(questions))\n",
        "    print(f\"\\nProcessing batch from {batch_start+1} to {batch_end}\")\n",
        "\n",
        "    # Process each question in the batch\n",
        "    for i in range(batch_start, batch_end):\n",
        "        question = questions[i]\n",
        "        print(f\"\\n\\n{'='*80}\\nProcessing question {i+1}/{len(questions)}:\\n{question}\\n{'='*80}\")\n",
        "\n",
        "        # Update status\n",
        "        results_tracking.loc[i, \"Status\"] = \"Processing\"\n",
        "        display(results_tracking.iloc[i:i+1])\n",
        "\n",
        "        # Generate factual answer\n",
        "        print(\"\\nGenerating factual answer...\")\n",
        "        factual_prompt = f\"Answer this Class 7 NCERT Science question factually and directly: {question}\"\n",
        "        try:\n",
        "            factual_response = call_groq_with_retry(\n",
        "                prompt=factual_prompt,\n",
        "                model=\"llama3-70b-8192\",\n",
        "                max_tokens=500\n",
        "            )\n",
        "            factual_answer = factual_response.choices[0].message.content\n",
        "            print(f\"Factual answer: {factual_answer[:100]}...\")\n",
        "            results_tracking.loc[i, \"Factual Answer\"] = factual_answer[:50] + \"...\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating factual answer: {e}\")\n",
        "            factual_answer = f\"Error: Could not generate factual answer - {str(e)}\"\n",
        "            results_tracking.loc[i, \"Status\"] = \"Error-Factual\"\n",
        "\n",
        "        # Generate socratic dialogue\n",
        "        print(\"\\nGenerating socratic dialogue...\")\n",
        "        socratic_prompt = f\"\"\"\n",
        "        Create a socratic dialogue between a teacher and student for this 7th grade NCERT Science question:\n",
        "        \"{question}\"\n",
        "\n",
        "        The teacher should NOT give direct answers but guide the student through reasoning steps.\n",
        "        The teacher should ask questions that help the student think and discover the answer themselves.\n",
        "\n",
        "        Format the dialogue as a JSON array with alternating 'teacher' and 'student' roles like this:\n",
        "        [\n",
        "          {{\"role\": \"teacher\", \"content\": \"First teacher message\"}},\n",
        "          {{\"role\": \"student\", \"content\": \"First student response\"}},\n",
        "          {{\"role\": \"teacher\", \"content\": \"Second teacher message\"}},\n",
        "          ...and so on\n",
        "        ]\n",
        "\n",
        "        Ensure the dialogue has at least 3-4 exchanges and leads to understanding.\n",
        "        Always start with the teacher role and end with the teacher providing a concluding explanation.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            socratic_response = call_groq_with_retry(\n",
        "                prompt=socratic_prompt,\n",
        "                model=\"llama3-70b-8192\",\n",
        "                max_tokens=2000\n",
        "            )\n",
        "            socratic_text = socratic_response.choices[0].message.content\n",
        "            socratic_dialogue = parse_dialogue(socratic_text)\n",
        "\n",
        "            # Print a sample of the dialogue\n",
        "            print(f\"\\nDialogue has {len(socratic_dialogue)} turns. Sample:\")\n",
        "            for turn in socratic_dialogue[:2]:  # Show first 2 turns\n",
        "                print(f\"{turn['role'].upper()}: {turn['content'][:100]}...\")\n",
        "\n",
        "            results_tracking.loc[i, \"Dialogue Turns\"] = len(socratic_dialogue)\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating socratic dialogue: {e}\")\n",
        "            socratic_dialogue = [\n",
        "                {\"role\": \"teacher\", \"content\": f\"Error: Could not generate dialogue - {str(e)}\"}\n",
        "            ]\n",
        "            results_tracking.loc[i, \"Status\"] = \"Error-Dialogue\"\n",
        "            results_tracking.loc[i, \"Dialogue Turns\"] = 0\n",
        "\n",
        "        # Create example and add to results\n",
        "        example = {\n",
        "            \"question\": question,\n",
        "            \"rejected\": factual_answer,\n",
        "            \"chosen\": socratic_dialogue\n",
        "        }\n",
        "\n",
        "        results.append(example)\n",
        "\n",
        "        # Update status\n",
        "        results_tracking.loc[i, \"Status\"] = \"Completed\"\n",
        "        display(results_tracking.iloc[i:i+1])\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (i + 1) % CHECKPOINT_FREQUENCY == 0 or i == len(questions) - 1:\n",
        "            checkpoint_file = f\"{PROJECT_DIR}/checkpoint_{i+1}.json\"\n",
        "            with open(checkpoint_file, \"w\") as f:\n",
        "                json.dump(results, f, indent=2)\n",
        "            print(f\"\\nCheckpoint saved to {checkpoint_file}\")\n",
        "\n",
        "        # Add a small delay to avoid rate limits\n",
        "        time.sleep(1)\n",
        "\n",
        "    # Save full results at the end of each batch\n",
        "    full_results_file = f\"{PROJECT_DIR}/full_results_{batch_end}.json\"\n",
        "    with open(full_results_file, \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"Full results saved to {full_results_file}\")\n",
        "\n",
        "# Save the final dataset\n",
        "final_filename = f\"{PROJECT_DIR}/socratic_dpo_dataset_final.json\"\n",
        "with open(final_filename, \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"\\nDataset creation complete! Final dataset saved to {final_filename}\")\n",
        "\n",
        "# Generate summary statistics\n",
        "dialogue_lengths = [len(ex[\"chosen\"]) for ex in results]\n",
        "factual_lengths = [len(ex[\"rejected\"].split()) for ex in results]\n",
        "\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(f\"Total questions processed: {len(results)}\")\n",
        "print(f\"Average dialogue turns: {sum(dialogue_lengths)/len(dialogue_lengths):.1f}\")\n",
        "print(f\"Average factual answer length: {sum(factual_lengths)/len(factual_lengths):.1f} words\")\n",
        "\n",
        "# Display a formatted sample of the final dataset\n",
        "def display_example(example, index):\n",
        "    html = f\"\"\"\n",
        "    <div style=\"background-color:#f5f5f5; padding:15px; margin:10px 0; border-radius:5px;\">\n",
        "        <h3>Example {index+1}: {example['question']}</h3>\n",
        "        <div style=\"margin:10px 0; padding:10px; background-color:#ffe6e6; border-radius:5px;\">\n",
        "            <h4>Rejected (Factual Answer):</h4>\n",
        "            <p>{example['rejected']}</p>\n",
        "        </div>\n",
        "        <div style=\"margin:10px 0; padding:10px; background-color:#e6ffe6; border-radius:5px;\">\n",
        "            <h4>Chosen (Socratic Dialogue):</h4>\n",
        "    \"\"\"\n",
        "\n",
        "    for turn in example['chosen']:\n",
        "        if turn['role'] == 'teacher':\n",
        "            html += f'<p style=\"color:#0066cc\"><strong>Teacher:</strong> {turn[\"content\"]}</p>'\n",
        "        else:\n",
        "            html += f'<p style=\"color:#cc6600\"><strong>Student:</strong> {turn[\"content\"]}</p>'\n",
        "\n",
        "    html += \"\"\"\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    return html\n",
        "\n",
        "print(\"\\nDisplaying samples from the final dataset:\")\n",
        "for i in range(min(3, len(results))):\n",
        "    display(HTML(display_example(results[i], i)))"
      ],
      "metadata": {
        "id": "p10G719Nc5xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import json\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Make sure Google Drive is mounted\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Path to your project directory\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/socratic_project\"\n",
        "\n",
        "# Ask for the file to clean\n",
        "print(\"Available JSON files in your project directory:\")\n",
        "json_files = [f for f in os.listdir(PROJECT_DIR) if f.endswith('.json')]\n",
        "for i, file in enumerate(json_files):\n",
        "    print(f\"{i+1}. {file}\")\n",
        "\n",
        "file_idx = int(input(\"\\nEnter the number of the file you want to clean: \")) - 1\n",
        "if file_idx < 0 or file_idx >= len(json_files):\n",
        "    print(\"Invalid selection\")\n",
        "else:\n",
        "    input_file = \"socratic_dpo_dataset_final.json\"\n",
        "    input_path = os.path.join(PROJECT_DIR, input_file)\n",
        "\n",
        "    # Load the JSON file\n",
        "    with open(input_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    print(f\"\\nLoaded {len(data)} entries from {input_file}\")\n",
        "\n",
        "    # Define validation functions\n",
        "    def is_valid_entry(entry):\n",
        "        # Check if question exists and is not empty\n",
        "        if not entry.get(\"question\") or entry[\"question\"].strip() == \"\":\n",
        "            return False\n",
        "\n",
        "        # Check if rejected answer exists and is not error message\n",
        "        if not entry.get(\"rejected\") or entry[\"rejected\"].strip() == \"\" or \"Error:\" in entry[\"rejected\"]:\n",
        "            return False\n",
        "\n",
        "        # Check if chosen dialogue exists and has minimum turns\n",
        "        if not entry.get(\"chosen\") or not isinstance(entry[\"chosen\"], list) or len(entry[\"chosen\"]) < 2:\n",
        "            return False\n",
        "\n",
        "        # Check if dialogue has proper structure (teacher/student alternating)\n",
        "        roles = [turn.get(\"role\", \"\") for turn in entry[\"chosen\"]]\n",
        "        if not roles or roles[0] != \"teacher\":\n",
        "            return False\n",
        "\n",
        "        # Check if any turn has empty content\n",
        "        for turn in entry[\"chosen\"]:\n",
        "            if not turn.get(\"content\") or turn[\"content\"].strip() == \"\":\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    # Filter the data\n",
        "    valid_data = [entry for entry in data if is_valid_entry(entry)]\n",
        "\n",
        "    print(f\"Found {len(valid_data)} valid entries out of {len(data)} total\")\n",
        "    print(f\"Removed {len(data) - len(valid_data)} invalid entries\")\n",
        "\n",
        "    # Ask for confirmation\n",
        "    if input(\"\\nSave cleaned dataset? (yes/no): \").lower() in ['yes', 'y']:\n",
        "        output_file = input_file.split(\".\")[0] + \"_cleaned.json\"\n",
        "        output_path = os.path.join(PROJECT_DIR, output_file)\n",
        "\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(valid_data, f, indent=2)\n",
        "\n",
        "        print(f\"Cleaned dataset saved to {output_file}\")\n",
        "\n",
        "        # Display examples of removed entries if there are any\n",
        "        if len(data) != len(valid_data):\n",
        "            print(\"\\nExamples of removed entries:\")\n",
        "            removed = [entry for entry in data if not is_valid_entry(entry)]\n",
        "            for i, entry in enumerate(removed[:3]):  # Show up to 3 examples\n",
        "                print(f\"\\nInvalid Entry #{i+1}:\")\n",
        "                print(f\"Question: {entry.get('question', 'MISSING')}\")\n",
        "                print(f\"Rejected: {entry.get('rejected', 'MISSING')[:100]}...\" if entry.get('rejected') else \"MISSING\")\n",
        "                print(f\"Chosen: {len(entry.get('chosen', [])) if isinstance(entry.get('chosen'), list) else 'INVALID'} turns\")\n",
        "                if isinstance(entry.get('chosen'), list) and entry['chosen']:\n",
        "                    print(f\"First turn: {entry['chosen'][0].get('role', 'MISSING')} - {entry['chosen'][0].get('content', 'MISSING')[:50]}...\")"
      ],
      "metadata": {
        "id": "y_x0fbUYdtov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MYHBCHigzY_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}